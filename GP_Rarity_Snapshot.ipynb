{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "91Jcv8q35bEz"
      },
      "outputs": [],
      "source": [
        "timestamp = \"2023-05-04 08:00\" # Enter timestamp in UTC in this format 04 May 08AM UTC\n",
        "api_key = \"xxxxxxxx-yyyy-zzzz-aaaa-bbbbbbbbbbbb\" # Enter your API key\n",
        "garden_point_contract = \"0xFeffc0E5C9575576C1922978102afa2D803Dc93F\" # Enter garden point's contract\n",
        "ch_proxy = \"0x0b2e0bdaffd0881988f37057104977c9206fe481\" # Enter cyberhornets' proxy contract on kometh\n",
        "ch_comics = \"0x303Fd791674D67e1288f769B54699c170eEdE5e7\" # Enter cyberhornets' comic contract\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "cgT_1rUCqlWi"
      },
      "outputs": [],
      "source": [
        "# format for api_key\n",
        "# api_key = \"xxxxxxxx-yyyy-zzzz-aaaa-bbbbbbbbbbbb\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8Nj4DLXmTZ1",
        "outputId": "275a14f8-3558-4534-e41a-288d129a231c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: shroomdk in /Users/fcitra/opt/anaconda3/lib/python3.8/site-packages (1.0.2)\n",
            "Requirement already satisfied: urllib3==1.26.11 in /Users/fcitra/opt/anaconda3/lib/python3.8/site-packages (from shroomdk) (1.26.11)\n",
            "Requirement already satisfied: requests==2.28.1 in /Users/fcitra/opt/anaconda3/lib/python3.8/site-packages (from shroomdk) (2.28.1)\n",
            "Requirement already satisfied: pydantic==1.9.1 in /Users/fcitra/opt/anaconda3/lib/python3.8/site-packages (from shroomdk) (1.9.1)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/fcitra/opt/anaconda3/lib/python3.8/site-packages (from requests==2.28.1->shroomdk) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/fcitra/opt/anaconda3/lib/python3.8/site-packages (from requests==2.28.1->shroomdk) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/fcitra/opt/anaconda3/lib/python3.8/site-packages (from requests==2.28.1->shroomdk) (2020.6.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/fcitra/opt/anaconda3/lib/python3.8/site-packages (from pydantic==1.9.1->shroomdk) (3.7.4.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install shroomdk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "fEdyIR7pmZQc"
      },
      "outputs": [],
      "source": [
        "from shroomdk import ShroomDK\n",
        "\n",
        "# Initialize `ShroomDK` with your API Key\n",
        "sdk = ShroomDK(api_key)\n",
        "\n",
        "\n",
        "# First query is to get a block number for snapshot that corresponds to snapshot time\n",
        "sql_blocknumber = f\"\"\"\n",
        "    SELECT\n",
        "        block_timestamp, \n",
        "        block_number\n",
        "    FROM ethereum.core.ez_nft_transfers\n",
        "    WHERE date_trunc('minute', block_timestamp) = '{timestamp}'\n",
        "    ORDER BY block_timestamp DESC\n",
        "    LIMIT 1\n",
        "\"\"\"\n",
        "\n",
        "query_result_timestamp = sdk.query(sql_blocknumber)\n",
        "\n",
        "for record in query_result_timestamp.records:\n",
        "    snapshot = record['block_number']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "CYwC-A8ZmcQU"
      },
      "outputs": [],
      "source": [
        "# Parameters can be passed into SQL statements \n",
        "# via native string interpolation\n",
        "# Second query is to obtain token wallet balances during a particular block \n",
        "\n",
        "my_address = garden_point_contract # garden point contract\n",
        "\n",
        "sql = f\"\"\"\n",
        "    WITH wallets as(\n",
        "    SELECT \n",
        "        nft_to_address as wallet, \n",
        "        max(block_number) as last_transfer \n",
        "    FROM ethereum.core.ez_nft_transfers \n",
        "    WHERE nft_address = LOWER('{my_address}')\n",
        "    GROUP BY wallet\n",
        "    ),\n",
        "\n",
        "    first_data as(\n",
        "    SELECT\n",
        "        nft_to_address as owner,\n",
        "        tokenid\n",
        "    FROM ethereum.core.ez_nft_transfers\n",
        "    WHERE nft_address = LOWER('{my_address}')\n",
        "    AND block_number <= '{snapshot}'\n",
        "    QUALIFY RANK() OVER (\n",
        "        PARTITION BY tokenid \n",
        "        ORDER BY block_number DESC, event_index DESC) = 1        \n",
        "    )\n",
        "    SELECT *\n",
        "    FROM first_data\n",
        "    ORDER BY owner\n",
        "    \n",
        "\"\"\"\n",
        "\n",
        "# Run the query against Flipside's query engine \n",
        "# and await the results\n",
        "query_result_set = sdk.query(sql)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "# third sql is to retrieve the minters of cyberhornets\n",
        "\n",
        "sql_3 = f\"\"\"\n",
        "    with chc_mints as (\n",
        "    select\n",
        "      block_timestamp, \n",
        "      block_number, \n",
        "      event_type,\n",
        "      nft_address,\n",
        "      nft_from_address as sender, \n",
        "      nft_to_address as wallet, \n",
        "      tokenid,\n",
        "      erc1155_value \n",
        "    from ethereum.core.ez_nft_transfers\n",
        "    where nft_from_address = LOWER('{ch_proxy}')\n",
        "    and block_number <= '{snapshot}'\n",
        "    )\n",
        "\n",
        "    select wallet, sum(erc1155_value) as minted from chc_mints\n",
        "    group by wallet\n",
        "    order by minted DESC\n",
        "    \n",
        "\"\"\"\n",
        "\n",
        "# Run the query against Flipside's query engine \n",
        "# and await the results\n",
        "query_result_set_3 = sdk.query(sql_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fourth sql is to retrieve the holders of cyberhornets, regardless of when\n",
        "# and where they minted\n",
        "\n",
        "sql_4 = f\"\"\"   \n",
        "    with cyber_hornets as (\n",
        "    select\n",
        "        block_timestamp, \n",
        "        block_number, \n",
        "        event_type,\n",
        "        nft_address,\n",
        "        nft_from_address as sender, \n",
        "        nft_to_address as recipient, \n",
        "        tokenid,\n",
        "        erc1155_value \n",
        "    from ethereum.core.ez_nft_transfers\n",
        "    where nft_address = lower('{ch_comics}')\n",
        "    and block_number <= '{snapshot}'\n",
        "    ),\n",
        "\n",
        "    transfer_to as (\n",
        "    SELECT \n",
        "        recipient, \n",
        "        COUNT(*) as balance_in\n",
        "    FROM cyber_hornets\n",
        "    GROUP BY recipient),\n",
        "\n",
        "    transfer_from as (\n",
        "        SELECT \n",
        "            sender, \n",
        "            COUNT(*) as balance_out\n",
        "    FROM cyber_hornets\n",
        "    GROUP BY sender\n",
        "    ),\n",
        "\n",
        "    in_out as (\n",
        "    select \n",
        "        recipient, \n",
        "        balance_in, \n",
        "        COALESCE(balance_out, 0) as new_balance_out \n",
        "    from transfer_to\n",
        "    left join transfer_from on transfer_to.recipient = transfer_from.sender\n",
        "    )\n",
        "\n",
        "    SELECT \n",
        "        recipient, \n",
        "        balance_in, \n",
        "        new_balance_out, \n",
        "        balance_in - new_balance_out as bal\n",
        "    FROM in_out\n",
        "    order by bal desc \n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Run the query against Flipside's query engine \n",
        "# and await the results\n",
        "query_result_set_4 = sdk.query(sql_4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "QQzk6S4Zmu_a"
      },
      "outputs": [],
      "source": [
        "# create empty data frame container for garden point rarity holder\n",
        "data = []\n",
        "\n",
        "# convert sql run result into pandas dataframe\n",
        "for record in query_result_set.records:\n",
        "    owner = record['owner']\n",
        "    tokenid = record['tokenid']\n",
        "    data.append({'owner': owner, 'token_id': tokenid})\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# convert token id data type from object/string to integer\n",
        "df['token_id'] = df['token_id'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create empty data frame container for cyber hornets minters\n",
        "\n",
        "data_3 = []\n",
        "\n",
        "for record in query_result_set_3.records:\n",
        "    wallet = record['wallet']\n",
        "    minted = record['minted']\n",
        "    data_3.append({'wallet': wallet, 'minted': minted})\n",
        "df_3 = pd.DataFrame(data_3)\n",
        "\n",
        "# data frame for cyber hornets minters through kometh\n",
        "\n",
        "df_3['minted'] = df_3['minted'].astype(int)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create empty data frame container for cyber hornets holders\n",
        "\n",
        "data_4 = []\n",
        "\n",
        "for record in query_result_set_4.records:\n",
        "    wallet = record['recipient']\n",
        "    bal = record['bal']\n",
        "    data_4.append({'owner': wallet, 'Cyber Hornets': bal})\n",
        "df_4 = pd.DataFrame(data_4)\n",
        "\n",
        "# data frame for cyber hornets minters through kometh\n",
        "\n",
        "df_4['Cyber Hornets'] = df_4['Cyber Hornets'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "YrQSaC7omxS1"
      },
      "outputs": [],
      "source": [
        "# import garden point token metadata from github repository\n",
        "\n",
        "token_metadata_url = 'https://raw.githubusercontent.com/fcitra/GP-snapshot/main/GardenPoint%20Covers.csv'\n",
        "token_metadata_df = pd.read_csv(token_metadata_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "bGxk7o_hm0wP"
      },
      "outputs": [],
      "source": [
        "# merge token holders' snapshot with token metadata\n",
        "merged_df = pd.merge(df, token_metadata_df, on ='token_id', how = 'left')\n",
        "\n",
        "# fill missing metadata value for new tokens minted from burning event \n",
        "merged_df['Metadata'].fillna('RARE', inplace = True)\n",
        "\n",
        "# group token quantity based on holder wallet and rarity type\n",
        "grouped_df = merged_df.groupby(['owner', 'Metadata'])['Metadata'].size()\n",
        "\n",
        "# unstack grouped rows into columns\n",
        "df_unstack = grouped_df.unstack()\n",
        "\n",
        "# change NaN value into 0 \n",
        "df_unstack = df_unstack.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "# merged holders combine holders of Garden Point (including their rarities) and holders of Cyber Hornets\n",
        "\n",
        "merged_holders = pd.merge(df_unstack, df_4, on = 'owner', how = 'outer')\n",
        "merged_holders = merged_holders.fillna(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "wkw5YNrNm1Qw"
      },
      "outputs": [],
      "source": [
        "# create file csv file name for garden point holders\n",
        "# csv_name = 'snapshot_rarity_block_' + str(snapshot) + '.csv'\n",
        "# obsolete\n",
        "\n",
        "# create file csv for ch minters\n",
        "# csv_ch_minters_name = 'ch_minters_block_' + str(snapshot) + '.csv'\n",
        "\n",
        "# create file csv for ch holders\n",
        "# csv_ch_holders_name = 'ch_holders_block_' + str(snapshot) + '.csv'\n",
        "# obsolete\n",
        "\n",
        "# export dataframe of GP rarity holders to csv file \n",
        "# df_unstack.to_csv(csv_name, index = True)\n",
        "# obsolete\n",
        "\n",
        "# export dataframe of CH minters to csv file \n",
        "# df_3.to_csv(csv_ch_minters_name, index = True)\n",
        "\n",
        "# export dataframe of CH holders to csv file \n",
        "# df_4.to_csv(csv_ch_holders_name, index = True)\n",
        "# obsolete\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create file csv file name for holders of GP and CH\n",
        "csv_name = 'snapshot_GP_CH_block_' + str(snapshot) + '.csv'\n",
        "\n",
        "# create file csv for ch minters\n",
        "csv_ch_minters_name = 'ch_minters_block_' + str(snapshot) + '.csv'\n",
        "\n",
        "# export datafram of GP and CH holders to csv file\n",
        "merged_holders.to_csv(csv_name, index = True)\n",
        "\n",
        "# export dataframe of CH minters to csv file \n",
        "df_3.to_csv(csv_ch_minters_name, index = True)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "f19328809354835b6efb0b42dccd0f6561f99cdc90888a50a9b48e8c75d8c9e1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
